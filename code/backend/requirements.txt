# Octopus AI Backend Dependencies
# Python 3.10+

# ============================================================
# Core Framework
# ============================================================
fastapi==0.109.0
uvicorn[standard]==0.25.0
pydantic==2.5.0
python-multipart==0.0.6

# ============================================================
# AI/ML Models
# ============================================================
transformers==4.37.0
torch==2.1.2
torchvision==0.16.2
torchaudio==2.1.2

# Qwen3-VL dependencies
qwen-vl-utils==0.0.8
accelerate==0.26.1
bitsandbytes==0.42.0  # For INT4 quantization
flash-attn==2.5.0     # Optional: Flash Attention 2 (requires compute capability >= 8.0)

# InsightFace
insightface==0.7.3
onnxruntime-gpu==1.16.3
opencv-python==4.8.1.78

# FAISS
faiss-gpu==1.7.2

# Audio processing
librosa==0.10.1
soundfile==0.12.1
numpy==1.24.3

# ============================================================
# Utilities
# ============================================================
Pillow==10.1.0
aiofiles==23.2.1
python-dotenv==1.0.0
pyyaml==6.0.1

# ============================================================
# Monitoring & Logging
# ============================================================
prometheus-client==0.19.0
python-json-logger==2.0.7

# ============================================================
# Development (Optional)
# ============================================================
# pytest==7.4.3
# pytest-asyncio==0.21.1
# black==23.12.1
# flake8==7.0.0
# mypy==1.8.0

# ============================================================
# Version Notes
# ============================================================
# - torch: CUDA 12.1 compatible
# - transformers: Required for Qwen3-VL
# - bitsandbytes: Critical for INT4 quantization
# - flash-attn: Optional but highly recommended for A100/H100
# - faiss-gpu: Faster than CPU version
# - insightface: Requires onnxruntime-gpu for CUDA acceleration