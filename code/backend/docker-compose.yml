version: '3.8'

# Octopus AI Backend Services
# Professional GPU (A100/H100/L40S) required for production latency
# Consumer GPU (RTX 4090) will work but with 2-3Ã— slower inference

services:
  
  # ============================================================
  # NGINX - Reverse Proxy & SSL Termination
  # ============================================================
  nginx:
    image: nginx:alpine
    container_name: octopus_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - rtc_gateway
    restart: unless-stopped
    networks:
      - octopus_net
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ============================================================
  # RTC Gateway - Main Orchestrator
  # ============================================================
  rtc_gateway:
    build:
      context: .
      dockerfile: Dockerfile.rtc_gateway
    container_name: octopus_rtc_gateway
    environment:
      - RTC_APP_ID=${RTC_APP_ID}
      - RTC_APP_KEY=${RTC_APP_KEY}
      - QWEN3VL_URL=http://model_manager:8088
      - SENSEVOICE_URL=http://sensevoice:8081
      - DIA2_URL=http://model_manager:8088
      - EMOVIT_URL=http://emovit:8083
      - INSIGHTFACE_URL=http://insightface:8084
      - EMOTION_FUSION_URL=http://emotion_fusion:8085
      - ANIMATION_SYNC_URL=http://animation_sync:8086
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./logs/rtc_gateway:/logs
      - ./data:/data
    ports:
      - "8080:8080"
    depends_on:
      - model_manager
      - sensevoice
      - emovit
      - insightface
      - emotion_fusion
      - animation_sync
    restart: unless-stopped
    networks:
      - octopus_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ============================================================
  # Model Manager - Dynamic Qwen3-VL & DIA2 Loading
  # CRITICAL: Requires professional GPU for production latency
  # ============================================================
  model_manager:
    build:
      context: ./services
      dockerfile: Dockerfile.model_manager
    container_name: octopus_model_manager
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - TRANSFORMERS_CACHE=/models/cache
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - QWEN3VL_MODEL=Qwen/Qwen3-VL-30B-A3B-Instruct
      - DIA2_MODEL=/models/dia2
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./models/qwen3_vl:/models/qwen3_vl
      - ./models/dia2:/models/dia2
      - ./models/cache:/models/cache
    ports:
      - "8088:8088"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 64G
    restart: unless-stopped
    networks:
      - octopus_net
    shm_size: '32gb'  # Critical for large model loading
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s  # Long startup time for model loading

  # ============================================================
  # SenseVoice - Speech-to-Text + Audio Emotion
  # ============================================================
  sensevoice:
    build:
      context: ./services
      dockerfile: Dockerfile.sensevoice
    container_name: octopus_sensevoice
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_PATH=/models/sensevoice
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./models/sensevoice:/models/sensevoice
    ports:
      - "8081:8081"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    restart: unless-stopped
    networks:
      - octopus_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ============================================================
  # EmoVIT - Vision Emotion Detection
  # ============================================================
  emovit:
    build:
      context: ./services
      dockerfile: Dockerfile.emovit
    container_name: octopus_emovit
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_PATH=/models/emovit
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./models/emovit:/models/emovit
    ports:
      - "8083:8083"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    restart: unless-stopped
    networks:
      - octopus_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ============================================================
  # InsightFace - Face Recognition
  # ============================================================
  insightface:
    build:
      context: ./services
      dockerfile: Dockerfile.insightface
    container_name: octopus_insightface
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_PACK=buffalo_l
      - DATABASE_PATH=/data/users.db
      - FAISS_INDEX_PATH=/data/users.faiss
      - RECOGNITION_THRESHOLD=${RECOGNITION_THRESHOLD:-0.6}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./models/insightface:/models/insightface
      - ./data:/data
    ports:
      - "8084:8084"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    restart: unless-stopped
    networks:
      - octopus_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8084/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ============================================================
  # Emotion Fusion - Audio + Vision Emotion Fusion
  # ============================================================
  emotion_fusion:
    build:
      context: ./services
      dockerfile: Dockerfile.emotion_fusion
    container_name: octopus_emotion_fusion
    environment:
      - SPEAKING_AUDIO_WEIGHT=${SPEAKING_AUDIO_WEIGHT:-0.7}
      - SPEAKING_VISION_WEIGHT=${SPEAKING_VISION_WEIGHT:-0.3}
      - SILENT_AUDIO_WEIGHT=${SILENT_AUDIO_WEIGHT:-0.0}
      - SILENT_VISION_WEIGHT=${SILENT_VISION_WEIGHT:-1.0}
      - SMOOTHING_FACTOR=${SMOOTHING_FACTOR:-0.3}
      - VAD_THRESHOLD=${VAD_THRESHOLD:-0.02}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports:
      - "8085:8085"
    restart: unless-stopped
    networks:
      - octopus_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ============================================================
  # Animation Sync - Generate Animation Markers
  # ============================================================
  animation_sync:
    build:
      context: ./services
      dockerfile: Dockerfile.animation_sync
    container_name: octopus_animation_sync
    environment:
      - BLINK_INTERVAL_MS=${BLINK_INTERVAL_MS:-3000}
      - GAZE_SHIFT_INTERVAL_MS=${GAZE_SHIFT_INTERVAL_MS:-2000}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    ports:
      - "8086:8086"
    restart: unless-stopped
    networks:
      - octopus_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ============================================================
  # Prometheus - Metrics Collection (Optional)
  # ============================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: octopus_prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    restart: unless-stopped
    networks:
      - octopus_net
    profiles:
      - monitoring

  # ============================================================
  # Grafana - Metrics Visualization (Optional)
  # ============================================================
  grafana:
    image: grafana/grafana:latest
    container_name: octopus_grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - octopus_net
    profiles:
      - monitoring

# ============================================================
# Networks
# ============================================================
networks:
  octopus_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# ============================================================
# Volumes
# ============================================================
volumes:
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# ============================================================
# Usage Examples
# ============================================================
# 
# Start all services:
#   docker-compose up -d
# 
# Start with monitoring:
#   docker-compose --profile monitoring up -d
# 
# View logs:
#   docker-compose logs -f
#   docker-compose logs -f model_manager
# 
# Stop all services:
#   docker-compose down
# 
# Rebuild specific service:
#   docker-compose build model_manager
#   docker-compose up -d model_manager
# 
# Check service health:
#   docker-compose ps
# 
# Scale (if load balancing configured):
#   docker-compose up -d --scale emotion_fusion=3
# 
# GPU verification:
#   docker exec octopus_model_manager nvidia-smi
# 
# VRAM monitoring:
#   watch -n 1 "docker exec octopus_model_manager nvidia-smi"
# 
# Backup user database:
#   docker cp octopus_insightface:/data/users.db ./backup/
#   docker cp octopus_insightface:/data/users.faiss ./backup/
# 
# ============================================================